name: Daily Air Quality Predictions

on:
  schedule:
    # Ejecutar diariamente a las 6:00 AM UTC (7:00 AM Madrid)
    - cron: '0 6 * * *'
  workflow_dispatch:  # Permitir ejecuci√≥n manual

env:
  DB_HOST: ${{ secrets.DB_HOST }}
  DB_PORT: ${{ secrets.DB_PORT }}
  DB_NAME: ${{ secrets.DB_NAME }}
  DB_USER: ${{ secrets.DB_USER }}
  DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
  AEMET_API_KEY: ${{ secrets.AEMET_API_KEY }}

jobs:
  daily-predictions:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Setup R
      uses: r-lib/actions/setup-r@v2
      with:
        r-version: '4.5.1'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y \
          libcurl4-openssl-dev \
          libssl-dev \
          libxml2-dev \
          libpq-dev \
          libgdal-dev \
          libproj-dev \
          libgeos-dev \
          libudunits2-dev \
          libarchive-dev \
          cmake \
          pandoc \
          gdal-bin

    - name: Cache R packages
      uses: actions/cache@v4
      with:
        path: ${{ env.R_LIBS_USER }}
        key: ${{ runner.os }}-r-${{ hashFiles('DESCRIPTION', 'renv.lock') }}

    - name: Install R dependencies
      run: |
        R -e "
        # Instalar solo paquetes esenciales para predicciones
        packages <- c(
          'DBI', 'RPostgres', 'caret', 'randomForest', 'sf',
          'dplyr', 'logger', 'httr2', 'jsonlite', 'lubridate',
          'data.table', 'shiny', 'leaflet', 'plotly'
        )

        for(pkg in packages) {
          if (!requireNamespace(pkg, quietly = TRUE)) {
            install.packages(pkg)
            cat('‚úÖ Instalado:', pkg, '\n')
          } else {
            cat('‚ö° Ya disponible:', pkg, '\n')
          }
        }

        cat('‚úÖ Dependencias esenciales instaladas\n')
        "

    - name: Download latest trained model
      run: |
        # Limpiar modelos existentes y descargar el m√°s reciente
        rm -f models/modelos_caret_avanzados*.rds
        gh release download --pattern "modelos_caret_avanzados*.rds" --dir models/ || echo "No model found, skipping download"

        # Verificar que el modelo existe
        if [ ! -f models/modelos_caret_avanzados.rds ]; then
          echo "Error: No se pudo descargar el modelo"
          exit 1
        fi

        echo "‚úÖ Modelo descargado correctamente"
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Collect real-time data
      run: |
        Rscript R/meteo_forecast.R || echo "AEMET forecast failed, continuing..."
        Rscript -e "
        source('R/datos_realtime_fallback.R', local = TRUE)
        datos_actuales <- obtener_datos_tiempo_real(usar_fallback = TRUE)
        saveRDS(datos_actuales, 'data/realtime/datos_prediccion_latest.rds')
        cat('‚úÖ Datos actuales preparados\n')
        "
      continue-on-error: true

    - name: Generate predictions
      run: |
        # Crear directorios necesarios
        mkdir -p output data/realtime logs
        Rscript R/05_predicciones_horarias.R

    - name: Log predictions for retrospective analysis
      run: |
        Rscript -e "
        source('R/prediction_logging.R')

        # Registrar predicciones para an√°lisis futuro
        if (file.exists('output/predicciones_40h_latest.rds')) {
          success <- log_predictions_wrapper('output/predicciones_40h_latest.rds')

          if (success) {
            cat('‚úÖ Predicciones registradas en log\n')

            # Generar reporte de performance si hay datos suficientes
            reporte <- generar_reporte_performance('output/performance_report_latest.rds')

            if (length(reporte) > 0) {
              cat('üìä Reporte de performance generado\n')
            }
          } else {
            cat('‚ùå Error registrando predicciones\n')
          }
        }
        "

    - name: Update cloud database
      run: |
        # Sincronizar nuevos datos a la base de datos cloud
        Rscript -e "
        source('R/utils.R')

        # Conectar a BD y actualizar datos m√°s recientes
        con <- conectar_bd()

        # Aqu√≠ agregar√≠as l√≥gica para insertar solo datos nuevos
        # Por ahora, verificamos conexi√≥n
        cat('‚úÖ Conexi√≥n a cloud database exitosa\n')
        cat('üìä Tablas disponibles:', length(DBI::dbListTables(con)), '\n')

        DBI::dbDisconnect(con)
        "

    - name: Generate dashboard data
      run: |
        # Preparar datos para el dashboard
        Rscript -e "
        # Generar archivos de resumen para dashboard
        if (file.exists('output/predicciones_40h_latest.rds')) {
          cat('‚úÖ Predicciones generadas correctamente\n')
        } else {
          cat('‚ùå Error: No se generaron predicciones\n')
          quit(status = 1)
        }
        "

    - name: Upload prediction artifacts
      uses: actions/upload-artifact@v4
      with:
        name: daily-predictions-${{ github.run_number }}
        path: |
          output/predicciones_*.rds
          output/performance_report_*.rds
          output/mapas_realtime/
          data/realtime/
        retention-days: 7

    - name: Deploy to shinyapps.io
      run: |
        # Configurar credenciales de shinyapps.io
        Rscript -e "
        if (!requireNamespace('rsconnect', quietly = TRUE)) {
          install.packages('rsconnect')
        }

        library(rsconnect)

        # Configurar cuenta
        setAccountInfo(
          name = '${{ secrets.SHINYAPPS_NAME }}',
          token = '${{ secrets.SHINYAPPS_TOKEN }}',
          secret = '${{ secrets.SHINYAPPS_SECRET }}'
        )

        # Preparar archivos para deployment
        if (!dir.exists('deploy_temp')) dir.create('deploy_temp')

        # Copiar archivos de la app
        file.copy('app/', 'deploy_temp/', recursive = TRUE)
        file.copy('R/', 'deploy_temp/', recursive = TRUE)

        # Copiar datos de predicci√≥n m√°s recientes
        if (file.exists('output/predicciones_40h_latest.rds')) {
          if (!dir.exists('deploy_temp/data')) dir.create('deploy_temp/data')
          file.copy('output/predicciones_40h_latest.rds', 'deploy_temp/data/')
        }

        # Crear archivo de configuraci√≥n de BD para la app
        writeLines(
          paste0(
            'DB_HOST=\"${{ secrets.DB_HOST }}\"\n',
            'DB_PORT=\"${{ secrets.DB_PORT }}\"\n',
            'DB_NAME=\"${{ secrets.DB_NAME }}\"\n',
            'DB_USER=\"${{ secrets.DB_USER }}\"\n',
            'DB_PASSWORD=\"${{ secrets.DB_PASSWORD }}\"'
          ),
          'deploy_temp/.Renviron'
        )

        cat('‚úÖ Archivos preparados para deployment\n')

        # Deploy a shinyapps.io
        deployApp(
          appDir = 'deploy_temp/app',
          appName = 'madrid-air-quality',
          account = '${{ secrets.SHINYAPPS_NAME }}',
          forceUpdate = TRUE
        )

        cat('üöÄ App desplegada exitosamente en shinyapps.io\n')
        cat('üîó URL: https://${{ secrets.SHINYAPPS_NAME }}.shinyapps.io/madrid-air-quality/\n')
        "

    - name: Clean up deployment files
      run: |
        rm -rf deploy_temp
        echo "üßπ Archivos temporales limpiados"

    - name: Notification on failure
      if: failure()
      run: |
        echo "‚ùå Error en predicciones diarias"
        echo "üîç Revisar logs para diagnosticar el problema"
        # Aqu√≠ puedes agregar notificaciones por email/Slack si es necesario