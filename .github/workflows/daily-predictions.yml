name: Daily Air Quality Predictions

on:
  schedule:
    # Ejecutar diariamente a las 4:00 AM UTC (6:00 AM Madrid CEST)
    - cron: '0 4 * * *'
  workflow_dispatch:  # Permitir ejecuci√≥n manual

env:
  DB_HOST: ${{ secrets.DB_HOST }}
  DB_PORT: ${{ secrets.DB_PORT }}
  DB_NAME: ${{ secrets.DB_NAME }}
  DB_USER: ${{ secrets.DB_USER }}
  DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
  AEMET_API_KEY: ${{ secrets.AEMET_API_KEY }}
  RENV_CONFIG_AUTOLOADER_ENABLED: FALSE

jobs:
  daily-predictions:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Pull Docker image
      run: |
        echo "üê≥ Descargando imagen Docker desde GHCR..."
        docker pull ghcr.io/${{ github.repository }}/air-quality-predictor:latest

        echo "‚úÖ Imagen Docker descargada"
        docker images | grep air-quality-predictor

    - name: Verify Docker environment
      run: |
        echo "üê≥ Verificando entorno Docker"
        docker run --rm ghcr.io/${{ github.repository }}/air-quality-predictor:latest Rscript -e "
        critical <- c('ranger', 'sf', 'caret', 'dplyr', 'logger', 'xml2')
        for(pkg in critical) {
          if(requireNamespace(pkg, quietly = TRUE)) {
            cat('‚úÖ', pkg, '\n')
          } else {
            cat('‚ùå FALTANTE:', pkg, '\n')
            stop('Paquete cr√≠tico faltante en Docker image')
          }
        }
        cat('‚úÖ Todos los paquetes cr√≠ticos disponibles\n')
        "

    - name: Download latest trained models
      run: |
        # Crear directorio de modelos
        mkdir -p models

        # Descargar modelos RANGER ICA (5 contaminantes)
        echo "üì• Descargando modelos RANGER ICA..."
        gh release download --pattern "ranger_ica_*.rds" --dir models/ || echo "No RANGER models found, skipping download"

        # Verificar que existen los modelos ICA
        model_count=$(ls -1 models/ranger_ica_*.rds 2>/dev/null | wc -l)
        echo "‚úÖ Modelos RANGER ICA encontrados: $model_count"

        if [ "$model_count" -lt 5 ]; then
          echo "‚ö†Ô∏è Advertencia: Se esperaban 5 modelos ICA (NO2, PM10, PM2.5, O3, SO2)"
          echo "üí° Continuando con modelos disponibles..."
        fi
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Collect real-time data
      run: |
        # Crear directorios antes de ejecutar scripts
        mkdir -p data/realtime logs

        # Ejecutar scripts R en Docker con vol√∫menes montados
        docker run --rm \
          -v $(pwd):/app \
          -w /app \
          -e AEMET_API_KEY="${{ secrets.AEMET_API_KEY }}" \
          ghcr.io/${{ github.repository }}/air-quality-predictor:latest \
          Rscript R/meteo_forecast.R || echo "AEMET forecast failed, continuing..."

        docker run --rm \
          -v $(pwd):/app \
          -w /app \
          ghcr.io/${{ github.repository }}/air-quality-predictor:latest \
          Rscript -e "
          source('R/datos_realtime_fallback.R', local = TRUE)
          datos_actuales <- obtener_datos_tiempo_real(usar_fallback = FALSE)  # Usar datos REALES
          saveRDS(datos_actuales, 'data/realtime/datos_prediccion_latest.rds')
          cat('‚úÖ Datos actuales preparados\n')
          "
      continue-on-error: true

    # TEMPORARILY DISABLED: Models too large for GitHub Actions 7GB RAM limit
    # NO2 model: 2GB disk ‚Üí 8.9GB memory (exceeds limit)
    # TODO: Retrain models with fewer trees (ntree=300 instead of 500)
    # For now, generate predictions locally and upload to artifacts
    - name: Generate predictions
      if: false  # Disabled until models are retrained
      timeout-minutes: 30  # Timeout de 30 minutos (antes sin l√≠mite)
      run: |
        # Crear directorios necesarios
        mkdir -p output data/realtime logs

        # Mostrar memoria disponible ANTES de predicciones
        echo "üíæ Memoria disponible:"
        free -h

        # Ejecutar predicciones con optimizaci√≥n de memoria en Docker
        docker run --rm \
          -v $(pwd):/app \
          -w /app \
          -e DB_HOST="${{ secrets.DB_HOST }}" \
          -e DB_PORT="${{ secrets.DB_PORT }}" \
          -e DB_NAME="${{ secrets.DB_NAME }}" \
          -e DB_USER="${{ secrets.DB_USER }}" \
          -e DB_PASSWORD="${{ secrets.DB_PASSWORD }}" \
          ghcr.io/${{ github.repository }}/air-quality-predictor:latest \
          Rscript R/05_predicciones_horarias.R

        # Mostrar memoria DESPU√âS de predicciones
        echo "üíæ Memoria despu√©s de predicciones:"
        free -h

    - name: Log predictions for retrospective analysis
      run: |
        docker run --rm \
          -v $(pwd):/app \
          -w /app \
          ghcr.io/${{ github.repository }}/air-quality-predictor:latest \
          Rscript -e "
          # Logging b√°sico sin conexi√≥n a BD (por ahora)
          if (file.exists('output/predicciones_40h_latest.rds')) {
            predicciones <- readRDS('output/predicciones_40h_latest.rds')
            cat('‚úÖ Predicciones cargadas:', nrow(predicciones), 'registros\n')

            # Generar resumen b√°sico
            resumen <- list(
              timestamp = Sys.time(),
              total_predicciones = nrow(predicciones),
              estaciones = length(unique(predicciones\$id_estacion)),
              contaminantes = length(unique(predicciones\$contaminante)),
              rango_valores = range(predicciones\$prediccion, na.rm = TRUE)
            )

            # Guardar resumen
            saveRDS(resumen, 'output/resumen_predicciones_latest.rds')
            cat('üìä Resumen de predicciones generado\n')
          } else {
            cat('‚ùå No se encontraron predicciones para logging\n')
          }
          "
      continue-on-error: true

    - name: Update cloud database
      run: |
        # Verificar conexi√≥n a BD cloud (opcional)
        docker run --rm \
          -v $(pwd):/app \
          -w /app \
          -e DB_HOST="${{ secrets.DB_HOST }}" \
          -e DB_PORT="${{ secrets.DB_PORT }}" \
          -e DB_NAME="${{ secrets.DB_NAME }}" \
          -e DB_USER="${{ secrets.DB_USER }}" \
          -e DB_PASSWORD="${{ secrets.DB_PASSWORD }}" \
          ghcr.io/${{ github.repository }}/air-quality-predictor:latest \
          Rscript -e "
          tryCatch({
            library(DBI)
            library(RPostgres)

            # Conectar a BD cloud
            con <- dbConnect(RPostgres::Postgres(),
              host = Sys.getenv('DB_HOST'),
              port = as.integer(Sys.getenv('DB_PORT')),
              dbname = Sys.getenv('DB_NAME'),
              user = Sys.getenv('DB_USER'),
              password = Sys.getenv('DB_PASSWORD')
            )

            cat('‚úÖ Conexi√≥n a cloud database exitosa\n')
            cat('üìä Tablas disponibles:', length(DBI::dbListTables(con)), '\n')

            DBI::dbDisconnect(con)
          }, error = function(e) {
            cat('‚ö†Ô∏è No se pudo conectar a cloud database:', e\$message, '\n')
            cat('üí° Continuando sin actualizaci√≥n de BD...\n')
          })
          "
      continue-on-error: true

    - name: Update baseline tables
      run: |
        echo "üîÑ Actualizando tablas baseline estacional..."
        docker run --rm \
          -v $(pwd):/app \
          -w /app \
          -e DB_HOST="${{ secrets.DB_HOST }}" \
          -e DB_PORT="${{ secrets.DB_PORT }}" \
          -e DB_NAME="${{ secrets.DB_NAME }}" \
          -e DB_USER="${{ secrets.DB_USER }}" \
          -e DB_PASSWORD="${{ secrets.DB_PASSWORD }}" \
          ghcr.io/${{ github.repository }}/air-quality-predictor:latest \
          Rscript R/06_actualizar_baseline.R

        echo "‚úÖ Baseline actualizado (si hab√≠a datos nuevos)"
      continue-on-error: true

    - name: Generate dashboard data
      run: |
        # Crear todos los directorios que podr√≠an necesitarse
        mkdir -p app/www/mapas_horas app/www/horas app/www/logos output data/realtime logs models

        # Madrid mask se genera autom√°ticamente inline en generar_mapas_por_hora.R
        echo "üó∫Ô∏è Madrid mask se generar√° inline en generar_mapas_por_hora.R"

        # Generar mapas e im√°genes para el dashboard con Docker
        echo "üó∫Ô∏è Generando mapas por hora..."
        if ! docker run --rm -v $(pwd):/app -w /app ghcr.io/${{ github.repository }}/air-quality-predictor:latest Rscript generar_mapas_por_hora.R; then
          echo "‚ùå Error generando mapas por hora"
          echo "Creando mapas de fallback..."
          mkdir -p app/www/mapas_horas
          echo "Mapas no disponibles" > app/www/mapas_horas/placeholder.txt
        fi

        echo "üìä Generando im√°genes por hora..."
        if ! docker run --rm -v $(pwd):/app -w /app ghcr.io/${{ github.repository }}/air-quality-predictor:latest Rscript generar_imagenes_por_hora.R; then
          echo "‚ùå Error generando im√°genes por hora"
          echo "Creando im√°genes de fallback..."
          mkdir -p app/www/horas
          echo "Im√°genes no disponibles" > app/www/horas/placeholder.txt
        fi

        # Copiar datos al directorio app para Shiny
        echo "üì¶ Copiando datos al directorio app..."
        mkdir -p app/data
        cp output/predicciones_40h_latest.rds app/data/ || echo "Failed to copy predicciones"
        cp output/meteo_40h_latest.rds app/data/ || echo "Failed to copy meteo"

        # Verificar archivos generados con Docker
        docker run --rm -v $(pwd):/app -w /app ghcr.io/${{ github.repository }}/air-quality-predictor:latest Rscript -e "
        # Verificar predicciones y archivos dashboard
        if (file.exists('output/predicciones_40h_latest.rds')) {
          cat('‚úÖ Predicciones generadas correctamente\n')
        } else {
          cat('‚ùå Error: No se generaron predicciones\n')
        }

        # Verificar mapas animados y archivos dashboard
        cat('=== VERIFICACI√ìN ARCHIVOS DASHBOARD ===\n')

        # Verificar mapas por hora (cr√≠ticos para animaci√≥n)
        # 5 contaminantes ICA oficiales
        contaminantes <- c('no2', 'pm10', 'pm25', 'o3', 'so2')
        mapas_encontrados <- 0
        mapas_esperados <- 0

        for(cont in contaminantes) {
          for(hora in 1:10) {
            mapas_esperados <- mapas_esperados + 1
            archivo_mapa <- paste0('app/www/mapas_horas/mapa_', cont, '_hora_', sprintf('%02d', hora), '.png')
            if(file.exists(archivo_mapa)) {
              mapas_encontrados <- mapas_encontrados + 1
            }
          }
        }

        cat('üìä Mapas animados:', mapas_encontrados, 'de', mapas_esperados, 'generados\n')

        if(mapas_encontrados == 0) {
          cat('‚ùå ERROR CR√çTICO: No se generaron mapas animados\n')
          cat('üí° La animaci√≥n no funcionar√° en la web\n')
        } else if(mapas_encontrados < mapas_esperados) {
          cat('‚ö†Ô∏è ADVERTENCIA: Mapas incompletos, algunas horas no tendr√°n animaci√≥n\n')
        } else {
          cat('‚úÖ Todos los mapas animados generados correctamente\n')
        }

        # Verificar algunas im√°genes espec√≠ficas
        imagenes_criticas <- c(
          'app/www/mapas_horas/mapa_no2_hora_01.png',
          'app/www/mapas_horas/mapa_pm10_hora_01.png',
          'app/www/horas/no2_hora_01.png'
        )

        for(img in imagenes_criticas) {
          if(file.exists(img)) {
            cat('‚úÖ Imagen cr√≠tica:', basename(img), 'OK\n')
          } else {
            cat('‚ùå Imagen cr√≠tica FALTANTE:', basename(img), '\n')
          }
        }
        "

    - name: Upload prediction artifacts
      uses: actions/upload-artifact@v4
      with:
        name: daily-predictions-${{ github.run_number }}
        path: |
          output/predicciones_*.rds
          output/performance_report_*.rds
          output/mapas_realtime/
          data/realtime/
        retention-days: 7

    - name: Deploy to shinyapps.io
      run: |
        # Configurar credenciales de shinyapps.io y desplegar con Docker
        docker run --rm \
          -v $(pwd):/app \
          -w /app \
          ghcr.io/${{ github.repository }}/air-quality-predictor:latest \
          Rscript -e "
        if (!requireNamespace('rsconnect', quietly = TRUE)) {
          install.packages('rsconnect')
        }

        library(rsconnect)

        # Configurar cuenta
        setAccountInfo(
          name = '${{ secrets.SHINYAPPS_NAME }}',
          token = '${{ secrets.SHINYAPPS_TOKEN }}',
          secret = '${{ secrets.SHINYAPPS_SECRET }}'
        )

        # Preparar archivos para deployment
        if (!dir.exists('deploy_temp')) dir.create('deploy_temp')

        # Copiar archivos de la app
        file.copy('app/', 'deploy_temp/', recursive = TRUE)
        file.copy('R/', 'deploy_temp/', recursive = TRUE)

        # Verificar logo de la app
        logo_path <- 'deploy_temp/app/www/kinelytic-header-logo-white.png'
        if(file.exists(logo_path)) {
          cat('‚úÖ Logo copiado correctamente\n')
        } else {
          cat('‚ùå ERROR: Logo NO encontrado en', logo_path, '\n')
          cat('‚ö†Ô∏è La app se desplegar√° sin logo\n')
        }

        # Verificar que se copiaron los mapas animados
        mapas_copiados <- length(list.files('deploy_temp/app/www/mapas_horas/', pattern = '*.png', recursive = TRUE))
        cat('üìä Mapas copiados para deployment:', mapas_copiados, '\n')

        if(mapas_copiados == 0) {
          cat('‚ö†Ô∏è ADVERTENCIA: No se encontraron mapas PNG para deployment\n')
          cat('üí° La animaci√≥n no funcionar√° en shinyapps.io\n')
        }

        # Copiar datos de predicci√≥n m√°s recientes al directorio app
        if (!dir.exists('deploy_temp/app/data')) dir.create('deploy_temp/app/data')

        if (file.exists('output/predicciones_40h_latest.rds')) {
          file.copy('output/predicciones_40h_latest.rds', 'deploy_temp/app/data/')
        }

        if (file.exists('output/meteo_40h_latest.rds')) {
          file.copy('output/meteo_40h_latest.rds', 'deploy_temp/app/data/')
        }

        # Crear archivo de configuraci√≥n de BD para la app
        writeLines(
          paste0(
            'DB_HOST=\"${{ secrets.DB_HOST }}\"\n',
            'DB_PORT=\"${{ secrets.DB_PORT }}\"\n',
            'DB_NAME=\"${{ secrets.DB_NAME }}\"\n',
            'DB_USER=\"${{ secrets.DB_USER }}\"\n',
            'DB_PASSWORD=\"${{ secrets.DB_PASSWORD }}\"'
          ),
          'deploy_temp/.Renviron'
        )

        cat('‚úÖ Archivos preparados para deployment\n')

        # Deploy a shinyapps.io
        deployApp(
          appDir = 'deploy_temp/app',
          appName = 'madrid-air-quality',
          account = '${{ secrets.SHINYAPPS_NAME }}',
          forceUpdate = TRUE
        )

        cat('üöÄ App desplegada exitosamente en shinyapps.io\n')
        cat('üîó URL: https://${{ secrets.SHINYAPPS_NAME }}.shinyapps.io/madrid-air-quality/\n')
        "

    - name: Send success notification
      if: success()
      uses: dawidd6/action-send-mail@v3
      with:
        server_address: smtp.gmail.com
        server_port: 587
        username: ${{ secrets.GMAIL_USERNAME }}
        password: ${{ secrets.GMAIL_APP_PASSWORD }}
        subject: "‚úÖ Predicciones diarias completadas - Madrid Air Quality"
        body: |
          Pipeline de predicciones ejecutado exitosamente.

          üéØ Dashboard actualizado: https://${{ secrets.SHINYAPPS_NAME }}.shinyapps.io/madrid-air-quality/
          üìä Workflow: ${{ github.workflow }}
          üîÑ Run: ${{ github.run_number }}

          Pr√≥xima ejecuci√≥n programada en 24 horas.
        to: ${{ secrets.NOTIFICATION_EMAIL }}
        from: Madrid Air Quality System

    - name: Clean up deployment files
      run: |
        # Usar sudo para limpiar archivos creados por Docker con permisos root
        sudo rm -rf deploy_temp || echo "‚ö†Ô∏è No se pudo limpiar deploy_temp (permisos Docker)"
        echo "üßπ Archivos temporales limpiados"
      continue-on-error: true

    - name: Send email notification on failure
      if: failure()
      uses: dawidd6/action-send-mail@v3
      with:
        server_address: smtp.gmail.com
        server_port: 587
        username: ${{ secrets.GMAIL_USERNAME }}
        password: ${{ secrets.GMAIL_APP_PASSWORD }}
        subject: "‚ùå Error en predicciones diarias - Madrid Air Quality"
        body: |
          Ha ocurrido un error en el pipeline de predicciones diarias.

          Workflow: ${{ github.workflow }}
          Run: ${{ github.run_number }}
          Commit: ${{ github.sha }}

          Revisar logs en: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
        to: ${{ secrets.NOTIFICATION_EMAIL }}
        from: Madrid Air Quality System