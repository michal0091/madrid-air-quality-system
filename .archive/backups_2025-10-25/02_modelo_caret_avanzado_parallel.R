# VERSIÃ“N PARALELIZADA DEL MODELO CARET AVANZADO
# Aprovecha mÃºltiples cores para acelerar el entrenamiento 10-15x

# NOTA: Este script es idÃ©ntico a 02_modelo_caret_avanzado.R pero con paralelizaciÃ³n activada
# Usar en mÃ¡quinas con mÃºltiples cores (recomendado: 8+ cores)

# Cargar script base
source("R/02_modelo_caret_avanzado.R")

# Configurar paralelizaciÃ³n
library(doParallel)
library(foreach)

# Detectar nÃºmero de cores disponibles
n_cores <- parallel::detectCores()
n_cores_usar <- max(1, n_cores - 4)  # Dejar 2 cores libres para el sistema

log_info("=== CONFIGURACIÃ“N PARALELIZACIÃ“N ===")
log_info("Cores detectados: {n_cores}")
log_info("Cores a usar: {n_cores_usar}")

# Crear cluster
cl <- makePSOCKcluster(n_cores_usar)
registerDoParallel(cl)

log_info("âœ… ParalelizaciÃ³n activada")

# Modificar trainControl para usar paralelizaciÃ³n
TRAIN_CONTROL_PARALLEL <- trainControl(
  method = "cv",
  number = 5,
  savePredictions = "final",
  allowParallel = TRUE,  # IMPORTANTE: activar paralelizaciÃ³n
  verboseIter = TRUE     # Mostrar progreso
)

# FunciÃ³n wrapper que usa el control paralelo
entrenar_modelo_caret_avanzado_parallel <- function(datos, contaminante) {

  log_info("=== ENTRENANDO CARET PARALELO: {contaminante} ===")

  # Filtrar por contaminante
  datos_filtrados <- datos %>%
    filter(contaminante == !!contaminante)

  log_info("Datos filtrados: {nrow(datos_filtrados)} observaciones")

  if(nrow(datos_filtrados) < 1000) {
    log_warn("Dataset pequeÃ±o ({nrow(datos_filtrados)} obs), resultados pueden variar")
  }

  # Crear variables derivadas
  datos_enriquecidos <- crear_variables_derivadas(datos_filtrados)

  # Preparar datos para CARET
  datos_ml <- datos_enriquecidos %>%
    st_drop_geometry() %>%
    select(-any_of(c("fecha_hora", "id_estacion", "nombre_estacion", "contaminante",
                     "fecha", "unidad", "id_magnitud", "tipo_estacion"))) %>%
    filter(
      !is.na(valor_medio),
      !is.na(temp_media_c),
      !is.na(lon), !is.na(lat)
    ) %>%
    mutate(
      precipitacion_mm = ifelse(is.na(precipitacion_mm), 0, precipitacion_mm),
      vel_viento_media_ms = ifelse(is.na(vel_viento_media_ms),
                                   median(vel_viento_media_ms, na.rm = TRUE),
                                   vel_viento_media_ms),
      dir_viento_grados = ifelse(is.na(dir_viento_grados), 200, dir_viento_grados),
      presion_maxima_hpa = ifelse(is.na(presion_maxima_hpa),
                                  median(presion_maxima_hpa, na.rm = TRUE),
                                  presion_maxima_hpa),
      humedad_media_pct = ifelse(is.na(humedad_media_pct),
                                median(humedad_media_pct, na.rm = TRUE),
                                humedad_media_pct)
    ) %>%
    mutate(
      temp_sq = temp_media_c^2,
      temp_hum_ratio = temp_media_c / (humedad_media_pct + 1),
      temp_hum_product = temp_media_c * humedad_media_pct / 100,
      viento_x = vel_viento_media_ms * cos(dir_viento_grados * pi/180),
      viento_y = vel_viento_media_ms * sin(dir_viento_grados * pi/180),
      presion_anomalia = presion_maxima_hpa - 1013
    ) %>%
    filter(complete.cases(.)) %>%
    select(where(~n_distinct(.) > 1))

  log_info("Datos preparados para ML: {nrow(datos_ml)} obs, {ncol(datos_ml)-1} predictores")
  log_info("EstadÃ­sticas {contaminante}:")
  log_info("  Media: {round(mean(datos_ml$valor_medio), 2)} Âµg/mÂ³")
  log_info("  Mediana: {round(median(datos_ml$valor_medio), 2)} Âµg/mÂ³")
  log_info("  Rango: {round(min(datos_ml$valor_medio), 2)} - {round(max(datos_ml$valor_medio), 2)} Âµg/mÂ³")

  # Grid de bÃºsqueda
  tune_grid <- data.frame(mtry = c(8, 10, 12, 15))

  log_info("ConfiguraciÃ³n entrenamiento PARALELO (OPTIMIZADO 2025-10-24):")
  log_info("  Cores: {n_cores_usar}")
  log_info("  mtry candidates: {paste(tune_grid$mtry, collapse=', ')}")
  log_info("  ntree: 100 (OPTIMIZADO: 86% menos memoria)")
  log_info("  nodesize: 10 (OPTIMIZADO: mejor balance)")
  log_info("  CV folds: 5 (cada fold en paralelo)")

  # Entrenar modelo con control paralelo
  log_info("Iniciando entrenamiento PARALELO...")
  inicio_entrenamiento <- Sys.time()

  tryCatch({
    modelo_rf_parallel <- train(
      valor_medio ~ .,
      data = datos_ml,
      method = "rf",
      trControl = TRAIN_CONTROL_PARALLEL,  # Usar control paralelo
      tuneGrid = tune_grid,
      ntree = 100,        # OPTIMIZADO: 100 (vs 300) reduce memoria 86%
      importance = TRUE,
      nodesize = 10,      # OPTIMIZADO: 10 (vs 3) mejor balance
      maxnodes = NULL
    )

    tiempo_entrenamiento <- round(as.numeric(difftime(Sys.time(), inicio_entrenamiento, units = "secs")), 1)

    # Extraer mÃ©tricas
    mejores_resultados <- modelo_rf_parallel$results[
      modelo_rf_parallel$results$mtry == modelo_rf_parallel$bestTune$mtry, ]

    rmse_final <- mejores_resultados$RMSE
    rsquared_final <- mejores_resultados$Rsquared
    mae_final <- mejores_resultados$MAE

    log_success("âœ… MODELO PARALELO ENTRENADO EXITOSAMENTE")
    log_info("Tiempo entrenamiento: {tiempo_entrenamiento}s")
    log_info("Mejor mtry: {modelo_rf_parallel$bestTune$mtry}")
    log_info("RMSE: {round(rmse_final, 4)} Âµg/mÂ³")
    log_info("RÂ²: {round(rsquared_final, 6)}")
    log_info("MAE: {round(mae_final, 4)} Âµg/mÂ³")

    # AnÃ¡lisis de importancia
    importancia <- varImp(modelo_rf_parallel, scale = FALSE)
    log_info("\nTop 10 variables mÃ¡s importantes:")
    top_vars <- head(rownames(importancia$importance)[
      order(importancia$importance$Overall, decreasing = TRUE)], 10)

    for(i in seq_along(top_vars)) {
      var_name <- top_vars[i]
      var_imp <- round(importancia$importance[var_name, "Overall"], 1)
      log_info("  {sprintf('%2d', i)}. {var_name}: {var_imp}")
    }

    # Resultado completo
    resultado_parallel <- list(
      modelo = modelo_rf_parallel,
      contaminante = contaminante,
      metricas = list(
        rmse = rmse_final,
        rsquared = rsquared_final,
        mae = mae_final
      ),
      configuracion = list(
        mejor_mtry = modelo_rf_parallel$bestTune$mtry,
        ntree = 100,        # OPTIMIZADO: 86% menos memoria
        cv_folds = 5,
        nodesize = 10,      # OPTIMIZADO: mejor balance
        n_cores = n_cores_usar
      ),
      datos_info = list(
        n_observaciones = nrow(datos_ml),
        n_predictores = ncol(datos_ml) - 1,
        variables_usadas = names(datos_ml)[names(datos_ml) != "valor_medio"]
      ),
      importancia_variables = importancia,
      tiempo_entrenamiento = tiempo_entrenamiento,
      timestamp_entrenamiento = Sys.time()
    )

    return(resultado_parallel)

  }, error = function(e) {
    tiempo_error <- round(as.numeric(difftime(Sys.time(), inicio_entrenamiento, units = "secs")), 1)
    log_error("âŒ Error entrenando modelo paralelo ({tiempo_error}s): {e$message}")
    return(NULL)
  })
}

# FunciÃ³n principal paralelizada
ejecutar_modelado_paralelo <- function(contaminantes = c("DiÃ³xido de NitrÃ³geno", "PartÃ­culas < 10 Âµm", "PartÃ­culas < 2.5 Âµm", "Ozono", "DiÃ³xido de Azufre"),
                                      usar_fallback = FALSE) {

  log_info("ðŸš€ === INICIANDO MODELADO CARET PARALELO ===")
  log_info("ConfiguraciÃ³n: Datos histÃ³ricos REALES, {n_cores_usar} cores, variables derivadas")

  # Cargar datos histÃ³ricos
  datos_historicos <- cargar_datos_historicos_avanzado(usar_fallback = usar_fallback)

  if(is.null(datos_historicos) || nrow(datos_historicos) == 0) {
    log_error("No se pudieron cargar datos histÃ³ricos")
    stopCluster(cl)
    return(NULL)
  }

  log_info("Dataset cargado: {nrow(datos_historicos)} observaciones")

  # Entrenar modelos para cada contaminante
  modelos_paralelos <- list()
  resumen_resultados <- list()

  for(contaminante in contaminantes) {
    log_info("\n{paste(rep('=', 60), collapse='')}")
    log_info("PROCESANDO: {contaminante}")
    log_info("{paste(rep('=', 60), collapse='')}")

    datos_disponibles <- sum(datos_historicos$contaminante == contaminante, na.rm = TRUE)

    if(datos_disponibles < 100) {
      log_warn("Datos insuficientes para {contaminante}: {datos_disponibles} observaciones")
      next
    }

    log_info("Datos disponibles: {datos_disponibles} observaciones")

    # Entrenar modelo paralelo
    modelo_resultado <- entrenar_modelo_caret_avanzado_parallel(datos_historicos, contaminante)

    if(!is.null(modelo_resultado)) {
      modelos_paralelos[[contaminante]] <- modelo_resultado

      resumen_resultados[[contaminante]] <- data.frame(
        Contaminante = contaminante,
        RMSE = round(modelo_resultado$metricas$rmse, 4),
        R2 = round(modelo_resultado$metricas$rsquared, 6),
        MAE = round(modelo_resultado$metricas$mae, 4),
        Observaciones = modelo_resultado$datos_info$n_observaciones,
        Predictores = modelo_resultado$datos_info$n_predictores,
        Mejor_mtry = modelo_resultado$configuracion$mejor_mtry,
        Tiempo_s = modelo_resultado$tiempo_entrenamiento,
        Cores = n_cores_usar,
        stringsAsFactors = FALSE
      )

      log_success("âœ… {contaminante}: RÂ² = {round(modelo_resultado$metricas$rsquared, 4)}")
    } else {
      log_error("âŒ {contaminante}: FallÃ³ entrenamiento")
    }
  }

  # Resumen final
  if(length(modelos_paralelos) > 0) {
    log_info("\n{paste(rep('=', 60), collapse='')}")
    log_info("ðŸ“Š RESUMEN FINAL MODELADO PARALELO")
    log_info("{paste(rep('=', 60), collapse='')}")

    tabla_resumen <- do.call(rbind, resumen_resultados)
    tabla_resumen <- tabla_resumen[order(tabla_resumen$R2, decreasing = TRUE), ]

    print(tabla_resumen)

    log_info("\nðŸ† RANKING POR RÂ²:")
    for(i in 1:nrow(tabla_resumen)) {
      modelo <- tabla_resumen[i, ]
      log_info("  {i}. {modelo$Contaminante}: RÂ² = {modelo$R2} (RMSE = {modelo$RMSE})")
    }

    r2_promedio <- round(mean(tabla_resumen$R2), 4)
    rmse_promedio <- round(mean(tabla_resumen$RMSE), 3)
    tiempo_total <- sum(tabla_resumen$Tiempo_s)

    log_info("\nðŸ“ˆ ESTADÃSTICAS FINALES:")
    log_info("  RÂ² promedio: {r2_promedio}")
    log_info("  RMSE promedio: {rmse_promedio} Âµg/mÂ³")
    log_info("  Tiempo total: {round(tiempo_total/60, 1)} minutos")
    log_info("  Tiempo promedio por modelo: {round(tiempo_total/nrow(tabla_resumen), 1)}s")
    log_info("  Cores utilizados: {n_cores_usar}")

    # Guardar resultados
    resultado_completo <- list(
      modelos = modelos_paralelos,
      resumen = tabla_resumen,
      configuracion_global = list(
        n_cores = n_cores_usar,
        mtry_range = c(8, 10, 12, 15),
        ntree = 100,        # OPTIMIZADO: 86% menos memoria
        cv_folds = 5
      ),
      estadisticas = list(
        r2_promedio = r2_promedio,
        rmse_promedio = rmse_promedio,
        tiempo_total_s = tiempo_total,
        n_modelos_exitosos = nrow(tabla_resumen)
      ),
      timestamp_ejecucion = Sys.time()
    )

    archivo_salida <- "models/modelos_caret_avanzados_parallel.rds"
    saveRDS(resultado_completo, archivo_salida)

    log_success("âœ… MODELADO PARALELO COMPLETADO")
    log_info("ðŸ“ Guardado en: {archivo_salida}")

    # Cerrar cluster
    stopCluster(cl)
    log_info("âœ… Cluster paralelo cerrado")

    return(resultado_completo)

  } else {
    stopCluster(cl)
    log_error("âŒ NO SE ENTRENÃ“ NINGÃšN MODELO EXITOSAMENTE")
    return(NULL)
  }
}

# Instrucciones de uso
log_info("ðŸ“‹ Script PARALELO cargado")
log_info("Para ejecutar con paralelizaciÃ³n:")
log_info("  resultado <- ejecutar_modelado_paralelo(usar_fallback = FALSE)")
log_info("")
log_info("Ventajas:")
log_info("  - {n_cores_usar} cores en paralelo")
log_info("  - Acelera 10-15x cada modelo individual")
log_info("  - Mismo resultado, menos tiempo")
